{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import lmdb\n",
    "from torch.utils.data import random_split\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "\n",
    "class LmdbBaseDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Dataset class to\n",
    "    1. write Reaction networks objecs to lmdb\n",
    "    2. load lmdb files\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbBaseDataset, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.path = Path(self.config[\"src\"])\n",
    "\n",
    "        # Get metadata in case\n",
    "        # self.metadata_path = self.path.parent / \"metadata.npz\"\n",
    "        self.env = self.connect_db(self.path)\n",
    "\n",
    "        # If \"length\" encoded as ascii is present, use that\n",
    "        # If there are additional properties, there must be length.\n",
    "        length_entry = self.env.begin().get(\"length\".encode(\"ascii\"))\n",
    "        if length_entry is not None:\n",
    "            num_entries = pickle.loads(length_entry)\n",
    "        else:\n",
    "            # Get the number of stores data from the number of entries\n",
    "            # in the LMDB\n",
    "            num_entries = self.env.stat()[\"entries\"]\n",
    "\n",
    "        self._keys = list(range(num_entries))\n",
    "        self.num_samples = num_entries\n",
    "\n",
    "        # Get portion of total dataset\n",
    "        self.sharded = False\n",
    "        if \"shard\" in self.config and \"total_shards\" in self.config:\n",
    "            self.sharded = True\n",
    "            self.indices = range(self.num_samples)\n",
    "            # split all available indices into 'total_shards' bins\n",
    "            self.shards = np.array_split(\n",
    "                self.indices, self.config.get(\"total_shards\", 1)\n",
    "            )\n",
    "            # limit each process to see a subset of data based off defined shard\n",
    "            self.available_indices = self.shards[self.config.get(\"shard\", 0)]\n",
    "            self.num_samples = len(self.available_indices)\n",
    "\n",
    "        # TODO\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # if sharding, remap idx to appropriate idx of the sharded set\n",
    "        if self.sharded:\n",
    "            idx = self.available_indices[idx]\n",
    "\n",
    "        #!CHECK, _keys should be less then total numbers of keys as there are more properties.\n",
    "        datapoint_pickled = self.env.begin().get(f\"{self._keys[idx]}\".encode(\"ascii\"))\n",
    "\n",
    "        data_object = pickle.loads(datapoint_pickled)\n",
    "\n",
    "        # TODO\n",
    "        if self.transform is not None:\n",
    "            data_object = self.transform(data_object)\n",
    "\n",
    "        return data_object\n",
    "\n",
    "    def connect_db(self, lmdb_path=None):\n",
    "        env = lmdb.open(\n",
    "            str(lmdb_path),\n",
    "            subdir=False,\n",
    "            readonly=False,\n",
    "            lock=False,\n",
    "            readahead=True,\n",
    "            meminit=False,\n",
    "            max_readers=1,\n",
    "        )\n",
    "        return env\n",
    "\n",
    "    def close_db(self):\n",
    "        if not self.path.is_file():\n",
    "            for env in self.envs:\n",
    "                env.close()\n",
    "        else:\n",
    "            self.env.close()\n",
    "\n",
    "    def get_metadata(self, num_samples=100):\n",
    "        pass\n",
    "\n",
    "\n",
    "class LmdbMoleculeDataset(LmdbBaseDataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbMoleculeDataset, self).__init__(config=config, transform=transform)\n",
    "\n",
    "    @property\n",
    "    def charges(self):\n",
    "        charges = self.env.begin().get(\"charges\".encode(\"ascii\"))\n",
    "        return pickle.loads(charges)\n",
    "\n",
    "    @property\n",
    "    def ring_sizes(self):\n",
    "        ring_sizes = self.env.begin().get(\"ring_sizes\".encode(\"ascii\"))\n",
    "        return pickle.loads(ring_sizes)\n",
    "\n",
    "    @property\n",
    "    def elements(self):\n",
    "        elements = self.env.begin().get(\"elements\".encode(\"ascii\"))\n",
    "        return pickle.loads(elements)\n",
    "\n",
    "    @property\n",
    "    def feature_info(self):\n",
    "        feature_info = self.env.begin().get(\"feature_info\".encode(\"ascii\"))\n",
    "        return pickle.loads(feature_info)\n",
    "\n",
    "\n",
    "class LmdbReactionDataset(LmdbBaseDataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbReactionDataset, self).__init__(config=config, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"src\": \"/home/santiagovargas/dev/bondnet/bondnet/scripts/helpers/lmdb_big/molcule.lmdb\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = LmdbMoleculeDataset(config=config)\n",
    "len(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['molecule_index', 'molecule_graph', 'molecule_wrapper'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0},\n",
       " {3, 4, 5, 6, 7},\n",
       " {'C', 'H', 'N', 'O'},\n",
       " {'feature_size': {'atom': 12, 'bond': 8, 'global': 8},\n",
       "  'feature_scaler_mean': {'atom': tensor([1.9802, 0.4530, 0.2090, 0.0629, 0.0533, 0.0787, 0.0090, 0.0051, 0.3138,\n",
       "           0.4485, 0.0892, 0.1485]),\n",
       "   'bond': tensor([1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7535]),\n",
       "   'global': tensor([11.8440, 11.7270, 92.9330,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000])},\n",
       "  'feature_scaler_std': {'atom': tensor([1.1909, 0.7687, 0.4066, 0.2427, 0.2246, 0.2693, 0.0943, 0.0712, 0.4640,\n",
       "           0.4973, 0.2851, 0.3556]),\n",
       "   'bond': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9680]),\n",
       "   'global': tensor([ 6.5702,  7.2032, 53.8251,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.charges, mol.ring_sizes, mol.elements, mol.feature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"src\": \"/home/santiagovargas/dev/bondnet/bondnet/scripts/helpers/lmdb_big/reaction.lmdb\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction = LmdbReactionDataset(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': tensor([[0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'atom': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'bond': tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction[0][\"reaction_graph\"]\n",
    "reaction[0][\"reaction_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reaction_index', 'reaction_graph', 'reaction_feature', 'reaction_molecule_info', 'label', 'reverse_label', 'extra_info'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction[\n",
    "    0\n",
    "].keys()  # here key not euqal to reaction index as reaction data might be fail or shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bondnet.data.reaction_network import ReactionNetworkLMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_ntwk = ReactionNetworkLMDB(mol, reaction)\n",
    "# reaction[0]\n",
    "rxn_ntwk.subselect_reactions([4])[0][0][\"reaction_molecule_info\"][\"reactants\"][\n",
    "    \"reactants\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom_map': [{0: 0,\n",
       "   1: 1,\n",
       "   2: 2,\n",
       "   3: 3,\n",
       "   4: 4,\n",
       "   5: 5,\n",
       "   6: 6,\n",
       "   7: 7,\n",
       "   8: 8,\n",
       "   9: 9,\n",
       "   10: 10,\n",
       "   11: 11,\n",
       "   12: 12,\n",
       "   13: 13},\n",
       "  {0: 16, 1: 14, 2: 15}],\n",
       " 'bond_map': [{0: 17,\n",
       "   1: 13,\n",
       "   2: 5,\n",
       "   3: 3,\n",
       "   4: 2,\n",
       "   5: 11,\n",
       "   6: 6,\n",
       "   7: 10,\n",
       "   8: 14,\n",
       "   9: 1,\n",
       "   10: 0,\n",
       "   11: 4,\n",
       "   12: 16,\n",
       "   13: 18},\n",
       "  {0: 12, 1: 15}],\n",
       " 'init_reactants': [177, 178],\n",
       " 'reactants': [0, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_ntwk.subselect_reactions([4])[0][0][\"reaction_molecule_info\"][\"reactants\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_ntwk.subselect_reactions([4])[0][0][\"reaction_molecule_info\"][\"reactants\"][\n",
    "    \"reactants\"\n",
    "] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_ntwk.subselect_reactions([4])[0][0][\"reaction_molecule_info\"][\"reactants\"][\n",
    "    \"reactants\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if dictionary is mutable\n",
    "test = rxn_ntwk.subselect_reactions([4])[0][0][\"reaction_molecule_info\"][\"reactants\"]\n",
    "test[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test = rxn_ntwk.subselect_reactions([4])[0][0]\n",
    "test[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"] = [0]\n",
    "test[0] = 1\n",
    "test_copy = deepcopy(test)\n",
    "test_copy[0] = 1\n",
    "print(test[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'molecule_index': 0,\n",
       " 'molecule_graph': Graph(num_nodes={'atom': 15, 'bond': 14, 'global': 1},\n",
       "       num_edges={('atom', 'a2a', 'atom'): 15, ('atom', 'a2b', 'bond'): 28, ('atom', 'a2g', 'global'): 15, ('bond', 'b2a', 'atom'): 28, ('bond', 'b2b', 'bond'): 14, ('bond', 'b2g', 'global'): 14, ('global', 'g2a', 'atom'): 15, ('global', 'g2b', 'bond'): 14, ('global', 'g2g', 'global'): 1},\n",
       "       metagraph=[('atom', 'atom', 'a2a'), ('atom', 'bond', 'a2b'), ('atom', 'global', 'a2g'), ('bond', 'atom', 'b2a'), ('bond', 'bond', 'b2b'), ('bond', 'global', 'b2g'), ('global', 'atom', 'g2a'), ('global', 'bond', 'g2b'), ('global', 'global', 'g2g')]),\n",
       " 'molecule_wrapper': Molecule Summary\n",
       " Site: C (-0.1124, 1.6954, -0.6250)\n",
       " Site: N (-0.0176, 0.2572, -0.7638)\n",
       " Site: C (-0.8723, -0.5042, -0.2525)\n",
       " Site: C (-2.1147, -0.2901, 0.5344)\n",
       " Site: O (-0.6770, -1.8984, -0.5422)\n",
       " Site: C (-0.0621, -2.6138, 0.3801)\n",
       " Site: O (0.3844, -2.2258, 1.4259)\n",
       " Site: C (0.0309, -4.0320, -0.0299)\n",
       " Site: N (0.1239, -5.1496, -0.3020)\n",
       " Site: H (0.8303, 2.0690, -0.2102)\n",
       " Site: H (-0.2202, 2.1359, -1.6229)\n",
       " Site: H (-0.9386, 2.0426, 0.0059)\n",
       " Site: H (-2.2681, 0.7654, 0.7701)\n",
       " Site: H (-2.9698, -0.6627, -0.0454)\n",
       " Site: H (-2.0648, -0.8667, 1.4677)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bondnet.data.dataset import BaseDataset\n",
    "from bondnet.data.dataset import ReactionNetworkLMDBDataset\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetworkLMDB, collate_parallel_lmdb\n",
    "\n",
    "\n",
    "dataset = ReactionNetworkLMDBDataset(rxn_ntwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoaderReactionNetworkLMDB(\n",
    "    dataset, batch_size=4, shuffle=True, collate_fn=collate_parallel_lmdb\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['atom_map', 'bond_map', 'init_reactants', 'reactants'])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(dataloader))\n",
    "print((sample[1][\"reaction\"][0][\"reaction_molecule_info\"][\"reactants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "sample[1][\"reaction\"][0][\"reaction_molecule_info\"][\"reactants\"][\"reactants\"] = [0]\n",
    "print(sample[1][\"reaction\"][0][\"reaction_molecule_info\"][\"reactants\"][\"reactants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1][\"reaction\"][0][\"reaction_molecule_info\"][\"reactants\"][\"reactants\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: using GatedGCNConv\n"
     ]
    }
   ],
   "source": [
    "from bondnet.model.training_utils import load_model_lightning\n",
    "from bondnet.test_utils import get_defaults\n",
    "\n",
    "config = get_defaults()\n",
    "\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"extra_features\": [],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.1,\n",
    "        \"test_size\": 0.1,\n",
    "        \"batch_size\": 4,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "dataset_loc = \"../../../tests/data/testdata/barrier_100.json\"\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": dataset_loc,\n",
    "        \"target_var\": \"ts\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"extra_features\": [],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.2,\n",
    "        \"test_size\": 0.2,\n",
    "        \"batch_size\": 4,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "config_model = get_defaults()\n",
    "# update config with model settings\n",
    "for key, value in config_model[\"model\"].items():\n",
    "    config[\"model\"][key] = value\n",
    "for key, value in config_model[\"model\"].items():\n",
    "    config[\"model\"][key] = value\n",
    "from bondnet.data.datamodule import BondNetLightningDataModule\n",
    "\n",
    "dm = BondNetLightningDataModule(config)\n",
    "# feat_size, feat_name = dm.prepare_data()\n",
    "# config[\"model\"][\"in_feats\"] = feat_size\n",
    "# config[\"model\"][\"in_feats\"] = feat_size\n",
    "\n",
    "# config = get_defaults()\n",
    "config[\"model\"][\"in_feats\"] = dataset.feature_info[\"feature_size\"]\n",
    "\n",
    "model = load_model_lightning(config[\"model\"], load_dir=\"./test_lmdb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "import os\n",
    "from bondnet.data.utils import create_rxn_graph\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "nodes = [\"atom\", \"bond\", \"global\"]\n",
    "for it, (batched_graph, label) in enumerate(dataloader):\n",
    "    # print(feats)\n",
    "    # print(label)\n",
    "    # print(label)\n",
    "    feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "    target = label[\"value\"].view(-1).to(device)\n",
    "    # norm_atom = label[\"norm_atom\"]\n",
    "    norm_atom = None\n",
    "    # norm_bond = label[\"norm_bond\"]\n",
    "    norm_bond = None\n",
    "    stdev = torch.tensor([1.0])\n",
    "    # print(feats.keys())\n",
    "    # if device is not None:\n",
    "    # feats = {k: v.to(device) for k, v in feats.items()}\n",
    "    # target = target.to(device)\n",
    "    # norm_atom = norm_atom.to(device)\n",
    "    # norm_bond = norm_bond.to(device)\n",
    "    # stdev = stdev.to(device)\n",
    "\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"].keys())\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"][\"num_bonds_total\"])\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"][\"num_atoms_total\"])\n",
    "    reactions = label[\"reaction\"]\n",
    "    for nt, ft in feats.items():\n",
    "        batched_graph.nodes[nt].data.update({\"ft\": ft})\n",
    "\n",
    "    graphs = dgl.unbatch(batched_graph)\n",
    "    model(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "        reverse=False,\n",
    "    )\n",
    "\n",
    "    for rxn in reactions:\n",
    "        reactants = [\n",
    "            graphs[i] for i in rxn[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"]\n",
    "        ]\n",
    "        products = [\n",
    "            graphs[i] for i in rxn[\"reaction_molecule_info\"][\"products\"][\"products\"]\n",
    "        ]\n",
    "        # print(rxn[\"reaction_molecule_info\"][\"products\"][\"products\"])\n",
    "        # print(len(products))\n",
    "\n",
    "        mappings = rxn[\"reaction_molecule_info\"][\"mappings\"]\n",
    "        has_bonds = rxn[\"reaction_molecule_info\"][\"has_bonds\"]\n",
    "\n",
    "        g, fts = create_rxn_graph(\n",
    "            reactants=reactants,\n",
    "            products=products,\n",
    "            mappings=mappings,\n",
    "            device=device,\n",
    "            has_bonds=has_bonds,\n",
    "            reverse=False,\n",
    "            reactant_only=False,\n",
    "            empty_graph_fts=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:110: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1613: PossibleUserWarning: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 24/24 [00:01<00:00, 12.76it/s, loss=2.1, v_num=0, train_loss=1.910, train_r2=-1.30, train_l1=1.050, train_mse=1.950]"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_r2', 'train_l1', 'train_mse']. Condition can be set using `monitor` key in lr scheduler dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_325808/1373636847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         call._call_and_handle_interrupt(\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# since metric-based schedulers require access to metrics and those are not currently saved in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;31m# checkpoint, the plateau schedulers shouldn't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_lr_schedulers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# we manually decrease here because loggers expect that the same step is used when logging epoch-end metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36mupdate_lr_schedulers\u001b[0;34m(self, interval, update_plateau_schedulers)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mopt_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_idx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactive_optimizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36m_update_learning_rates\u001b[0;34m(self, interval, update_plateau_schedulers, opt_indices)\u001b[0m\n\u001b[1;32m    439\u001b[0m                             \u001b[0mavail_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                             raise MisconfigurationException(\n\u001b[0;32m--> 441\u001b[0;31m                                 \u001b[0;34mf\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                                 \u001b[0;34mf\" which is not available. Available metrics are: {avail_metrics}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                                 \u001b[0;34m\" Condition can be set using `monitor` key in lr scheduler dict\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_r2', 'train_l1', 'train_mse']. Condition can be set using `monitor` key in lr scheduler dict"
     ]
    }
   ],
   "source": [
    "project_name = \"test_multi_gpu\"\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    accumulate_grad_batches=5,\n",
    "    enable_progress_bar=True,\n",
    "    gradient_clip_val=1.0,\n",
    "    enable_checkpointing=True,\n",
    "    precision=32,\n",
    ")\n",
    "\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
