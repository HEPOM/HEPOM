{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d4d655-064f-4bd6-b9eb-4148d805051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb, argparse, torch, json\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetPrecomputed\n",
    "from bondnet.data.dataloader import DataLoaderPrecomputedReactionGraphs\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "from bondnet.utils import seed_torch\n",
    "from bondnet.model.training_utils import (\n",
    "    get_grapher,\n",
    "    LogParameters,\n",
    "    load_model_lightning,\n",
    ")\n",
    "\n",
    "seed_torch()\n",
    "torch.set_float32_matmul_precision(\"high\")  # might have to disable on older GPUs\n",
    "\n",
    "import torch.multiprocessing\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc1f8411-11dc-4118-b73a-1ba5c364a903",
   "metadata": {},
   "source": [
    "# check cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b938529-b2a2-4a55-b98b-605015208481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96233a8d-1caf-4489-bf33-587f2853bafa",
   "metadata": {},
   "source": [
    "# 1. model config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b04233-f39e-497a-8dc9-4858717b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"augment\": True,\n",
    "    \"batch_size\": 4,\n",
    "    \"debug\": False,\n",
    "    \"classifier\": False,\n",
    "    \"classif_categories\": 3,\n",
    "    \"cat_weights\": [1.0, 1.0, 1.0],\n",
    "    \"embedding_size\": 24,\n",
    "    \"epochs\": 100,\n",
    "    \"extra_features\": [\"bond_length\"],\n",
    "    \"extra_info\": [],\n",
    "    \"filter_species\": [3, 5],\n",
    "    \"fc_activation\": \"ReLU\",\n",
    "    \"fc_batch_norm\": True,\n",
    "    \"fc_dropout\": 0.2,\n",
    "    \"fc_hidden_size_1\": 256,\n",
    "    \"fc_hidden_size_shape\": \"flat\",\n",
    "    \"fc_num_layers\": 1,\n",
    "    \"gated_activation\": \"ReLU\",\n",
    "    \"gated_batch_norm\": False,\n",
    "    \"gated_dropout\": 0.1,\n",
    "    \"gated_graph_norm\": False,\n",
    "    \"gated_hidden_size_1\": 512,\n",
    "    \"gated_hidden_size_shape\": \"flat\",\n",
    "    \"gated_num_fc_layers\": 1,\n",
    "    \"gated_num_layers\": 2,\n",
    "    \"gated_residual\": True,\n",
    "    \"learning_rate\": 0.003,\n",
    "    \"precision\": 32,\n",
    "    \"loss\": \"mse\",\n",
    "    \"num_lstm_iters\": 3,\n",
    "    \"num_lstm_layers\": 1,\n",
    "    \"on_gpu\": True,\n",
    "    \"restore\": False,\n",
    "    \"target_var\": \"ts\",\n",
    "    \"target_var_transfer\": \"diff\",\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"max_epochs\": 100,\n",
    "    \"max_epochs_transfer\": 100,\n",
    "    \"transfer\": False,\n",
    "    \"filter_outliers\": True,\n",
    "}\n",
    "\n",
    "dataset_loc = \"../../../tests/data/testdata/barrier_100.json\"\n",
    "\n",
    "on_gpu = config[\"on_gpu\"]\n",
    "extra_keys = config[\"extra_features\"]\n",
    "debug = config[\"debug\"]\n",
    "precision = config[\"precision\"]\n",
    "\n",
    "if precision == \"16\" or precision == \"32\":\n",
    "    precision = int(precision)\n",
    "\n",
    "if on_gpu:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "extra_keys = config[\"extra_features\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20c83970-93e6-4817-ab6b-e7cb542d5de7",
   "metadata": {},
   "source": [
    "# 2. load json and processing it into Reaction networks graphs in cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed31fd9-bc47-4e79-a834-ad91395316c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file from: ../../../tests/data/testdata/barrier_100.json\n",
      "rxn raw len: 100\n",
      "Program finished in 0.6091721630655229 seconds\n",
      ".............failures.............\n",
      "reactions len: 89\n",
      "valid ind len: 89\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t11\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 89\n",
      "features: 214\n",
      "labels: 89\n",
      "molecules: 214\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 214\n",
      "number of graphs: 214\n",
      "prebuilding reaction graphs\n"
     ]
    }
   ],
   "source": [
    "dataset = ReactionNetworkDatasetPrecomputed(\n",
    "    grapher=get_grapher(extra_keys),\n",
    "    file=dataset_loc,\n",
    "    target=config[\"target_var\"],\n",
    "    classifier=config[\"classifier\"],\n",
    "    classif_categories=config[\"classif_categories\"],\n",
    "    filter_species=config[\"filter_species\"],\n",
    "    filter_outliers=config[\"filter_outliers\"],\n",
    "    filter_sparse_rxns=False,\n",
    "    debug=debug,\n",
    "    device=\"cpu\",\n",
    "    extra_keys=extra_keys,\n",
    "    extra_info=config[\"extra_info\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bacc825-ae81-4021-82df-c36cdca85e49",
   "metadata": {},
   "source": [
    "# 3. Write Reaction networks graphs to lmdb files in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ad40d7-6e34-4f6c-b1c4-1bf1820d790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, sys.path[0] + \"/../\")\n",
    "from bondnet.data.lmdb_dataset import LmdbDataset, CRNs2lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c48f2e4-f9a7-4833-b0cc-b4653c19439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker 0: Writing CRNs Objects into LMDBs: 100%|██████████| 30/30 [00:00<00:00, 628.71it/s]\n",
      "Worker 1: Writing CRNs Objects into LMDBs: 100%|██████████| 30/30 [00:00<00:00, 648.18it/s]\n",
      "\n",
      "Worker 2: Writing CRNs Objects into LMDBs: 100%|██████████| 29/29 [00:00<00:00, 624.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: ./lmdb_data/_tmp_data.0001.lmdb\n",
      "Deleted file: ./lmdb_data/_tmp_data.0000.lmdb-lock\n",
      "Deleted file: ./lmdb_data/_tmp_data.0002.lmdb-lock\n",
      "Deleted file: ./lmdb_data/_tmp_data.0001.lmdb-lock\n",
      "Deleted file: ./lmdb_data/_tmp_data.0000.lmdb\n",
      "Deleted file: ./lmdb_data/_tmp_data.0002.lmdb\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"out_path\": \"./lmdb_data/\",  # Update the directory path\n",
    "    \"num_workers\": 3,\n",
    "    \"output_file\": \"merged_data.lmdb\",\n",
    "}\n",
    "CRNs2lmdb(dataset, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b767271-6c05-4d07-a209-9c2b1412adb4",
   "metadata": {},
   "source": [
    "# 4. Load lmdb files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ed0823-84e9-4519-aa97-487f3e12bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lmdb = LmdbDataset({\"src\": \"./lmdb_data/merged_data.lmdb\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9658f898-a86e-4c1b-95a4-499b3a0554d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 float32 {'atom': 20, 'bond': 8, 'global': 7} {'atom': ['total degree', 'is in ring', 'total H', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'chemical symbol', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size'], 'bond': ['metal bond', 'ring inclusion', 'ring size', 'ring size', 'ring size', 'ring size', 'ring size', 'bond_length'], 'global': ['num atoms', 'num bonds', 'molecule weight', 'charge one hot', 'charge one hot', 'charge one hot', 'charge one hot']}\n"
     ]
    }
   ],
   "source": [
    "print(_lmdb.num_samples, _lmdb.dtype, _lmdb.feature_size, _lmdb.feature_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15a8828e-5395-4e47-a6a3-a80c937f20ec",
   "metadata": {},
   "source": [
    "# 5. Train BondNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b13fd3-4578-45f3-81cc-258ca60b8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>config_settings<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "augment             \t\t\tTrue                \n",
      "batch_size          \t\t\t24                  \n",
      "debug               \t\t\tFalse               \n",
      "classifier          \t\t\tFalse               \n",
      "classif_categories  \t\t\t3                   \n",
      "cat_weights         \t\t\t[1.0, 1.0, 1.0]     \n",
      "embedding_size      \t\t\t24                  \n",
      "epochs              \t\t\t100                 \n",
      "extra_features      \t\t\t['bond_length']     \n",
      "extra_info          \t\t\t[]                  \n",
      "filter_species      \t\t\t[3, 5]              \n",
      "fc_activation       \t\t\tReLU                \n",
      "fc_batch_norm       \t\t\tTrue                \n",
      "fc_dropout          \t\t\t0.2                 \n",
      "fc_hidden_size_1    \t\t\t256                 \n",
      "fc_hidden_size_shape\t\t\tflat                \n",
      "fc_num_layers       \t\t\t1                   \n",
      "gated_activation    \t\t\tReLU                \n",
      "gated_batch_norm    \t\t\tFalse               \n",
      "gated_dropout       \t\t\t0.1                 \n",
      "gated_graph_norm    \t\t\tFalse               \n",
      "gated_hidden_size_1 \t\t\t512                 \n",
      "gated_hidden_size_shape\t\t\tflat                \n",
      "gated_num_fc_layers \t\t\t1                   \n",
      "gated_num_layers    \t\t\t2                   \n",
      "gated_residual      \t\t\tTrue                \n",
      "learning_rate       \t\t\t0.003               \n",
      "precision           \t\t\t32                  \n",
      "loss                \t\t\tmse                 \n",
      "num_lstm_iters      \t\t\t3                   \n",
      "num_lstm_layers     \t\t\t1                   \n",
      "on_gpu              \t\t\tTrue                \n",
      "restore             \t\t\tFalse               \n",
      "target_var          \t\t\tts                  \n",
      "target_var_transfer \t\t\tdiff                \n",
      "weight_decay        \t\t\t0.0                 \n",
      "max_epochs          \t\t\t100                 \n",
      "max_epochs_transfer \t\t\t100                 \n",
      "transfer            \t\t\tFalse               \n",
      "filter_outliers     \t\t\tTrue                \n",
      "filter_sparse_rxns  \t\t\tFalse               \n",
      "in_feats            \t\t\t{'atom': 20, 'bond': 8, 'global': 7}\n",
      "gpu                 \t\t\tgpu                 \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>config_settings<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "log_save_dir = \"./logs_lightning/\"\n",
    "dict_for_model = {\n",
    "    \"extra_features\": extra_keys,\n",
    "    \"classifier\": False,\n",
    "    \"classif_categories\": config[\"classif_categories\"],\n",
    "    \"filter_species\": config[\"filter_species\"],\n",
    "    \"filter_outliers\": config[\"filter_outliers\"],\n",
    "    \"filter_sparse_rxns\": False,\n",
    "    \"debug\": debug,\n",
    "    \"in_feats\": dataset.feature_size,\n",
    "}\n",
    "config[\"batch_size\"] = 24\n",
    "\n",
    "config.update(dict_for_model)\n",
    "#! 2. split dataset.  train_validation_test_split is in bondnet dataset.\n",
    "trainset, valset, testset = train_validation_test_split(\n",
    "    _lmdb, validation=0.15, test=0.15\n",
    ")\n",
    "\n",
    "print(\">\" * 40 + \"config_settings\" + \"<\" * 40)\n",
    "for k, v in config.items():\n",
    "    print(\"{}\\t\\t\\t{}\".format(str(k).ljust(20), str(v).ljust(20)))\n",
    "\n",
    "print(\">\" * 40 + \"config_settings\" + \"<\" * 40)\n",
    "\n",
    "#! 3. dataloader\n",
    "val_loader = DataLoaderPrecomputedReactionGraphs(\n",
    "    valset, batch_size=len(valset), shuffle=False\n",
    ")\n",
    "test_loader = DataLoaderPrecomputedReactionGraphs(\n",
    "    testset, batch_size=len(testset), shuffle=False\n",
    ")\n",
    "train_loader = DataLoaderPrecomputedReactionGraphs(\n",
    "    trainset, batch_size=config[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "model = load_model_lightning(config, device=device, load_dir=log_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6359e11d-e075-458d-a1c8-2aa4a3e99fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msanti\u001b[0m (\u001b[33mhydro_homies\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/santiagovargas/dev/bondnet/bondnet/scripts/notebooks/wandb/run-20230702_152921-p43vpkqs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hydro_homies/test/runs/p43vpkqs' target=\"_blank\">likely-jazz-3</a></strong> to <a href='https://wandb.ai/hydro_homies/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hydro_homies/test' target=\"_blank\">https://wandb.ai/hydro_homies/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hydro_homies/test/runs/p43vpkqs' target=\"_blank\">https://wandb.ai/hydro_homies/test/runs/p43vpkqs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/santiagovargas/dev/bondnet/bondnet/scripts/notebooks/logs_lightning exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name          | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0  | embedding     | UnifySize           | 840   \n",
      "1  | gated_layers  | ModuleList          | 3.0 M \n",
      "2  | readout_layer | Set2SetThenCat      | 6.3 M \n",
      "3  | fc_layers     | ModuleList          | 656 K \n",
      "4  | loss          | WeightedMSELoss     | 0     \n",
      "5  | train_l1      | Metrics_WeightedMAE | 0     \n",
      "6  | train_r2      | R2Score             | 0     \n",
      "7  | val_l1        | Metrics_WeightedMAE | 0     \n",
      "8  | val_r2        | R2Score             | 0     \n",
      "9  | test_l1       | Metrics_WeightedMAE | 0     \n",
      "10 | test_r2       | R2Score             | 0     \n",
      "-------------------------------------------------------\n",
      "9.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 M     Total params\n",
      "39.743    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1613: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/4 [00:00<?, ?it/s, loss=6.46, v_num=pkqs, val_loss=4.030, val_l1=1.420, val_r2=-2.40, train_loss=3.030, train_l1=0.676, train_r2=0.246]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/santiagovargas/anaconda3/envs/bondnet_test/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_l1             1.279329776763916\n",
      "        test_loss            2.166151523590088\n",
      "         test_r2            -2.4590489864349365\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>test_l1</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_l1</td><td>▁█▆▃▂▁▁</td></tr><tr><td>train_loss</td><td>▂█▄▂▂▁▁</td></tr><tr><td>train_r2</td><td>▁██████</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>val_l1</td><td>▇█▃▁▁▁▁</td></tr><tr><td>val_loss</td><td>▇█▂▁▁▁▁</td></tr><tr><td>val_r2</td><td>▆▆▇█▁▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7</td></tr><tr><td>test_l1</td><td>1.27933</td></tr><tr><td>test_loss</td><td>2.16615</td></tr><tr><td>test_r2</td><td>-2.45905</td></tr><tr><td>train_l1</td><td>0.67576</td></tr><tr><td>train_loss</td><td>3.03002</td></tr><tr><td>train_r2</td><td>0.24625</td></tr><tr><td>trainer/global_step</td><td>7</td></tr><tr><td>val_l1</td><td>1.41806</td></tr><tr><td>val_loss</td><td>4.03243</td></tr><tr><td>val_r2</td><td>-2.40477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-jazz-3</strong> at: <a href='https://wandb.ai/hydro_homies/test/runs/p43vpkqs' target=\"_blank\">https://wandb.ai/hydro_homies/test/runs/p43vpkqs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230702_152921-p43vpkqs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_name = \"test\"\n",
    "with wandb.init(project=project_name) as run:\n",
    "    log_parameters = LogParameters()\n",
    "    logger_tb = TensorBoardLogger(log_save_dir, name=\"test_logs\")\n",
    "    logger_wb = WandbLogger(project=project_name, name=\"test_logs\")\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=log_save_dir,\n",
    "        filename=\"model_lightning_{epoch:02d}-{val_loss:.2f}\",\n",
    "        monitor=\"val_loss\",  # TODO\n",
    "        mode=\"min\",\n",
    "        auto_insert_metric_name=True,\n",
    "        save_last=True,\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", min_delta=0.00, patience=500, verbose=False, mode=\"min\"\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        accelerator=\"gpu\",\n",
    "        devices=[0],\n",
    "        accumulate_grad_batches=5,\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            lr_monitor,\n",
    "            log_parameters,\n",
    "            checkpoint_callback,\n",
    "        ],\n",
    "        enable_checkpointing=True,\n",
    "        default_root_dir=log_save_dir,\n",
    "        logger=[logger_tb, logger_wb],\n",
    "        precision=precision,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    trainer.test(model, test_loader)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb631c-6da4-4dde-b764-d95b18caff81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
