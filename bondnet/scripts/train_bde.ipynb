{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BonDNet \n",
    "\n",
    "In this notebook, we show how to train the BonDNet graph neural network model for bond dissociation energy (BDE) prediction. We only show how to train on CPUs. See [train_bde_distributed.py](./) for a script for training on GPUs (a single GPU or distributed training on multiple GPUs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from bondnet.data.dataset import ReactionNetworkDataset\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.featurizer import AtomFeaturizerMinimum, BondAsNodeFeaturizerMinimum, GlobalFeaturizer\n",
    "from bondnet.data.grapher import HeteroMoleculeGraph\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "from bondnet.scripts.create_label_file import read_input_files\n",
    "from bondnet.model.metric import WeightedL1Loss\n",
    "from bondnet.utils import seed_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "We work with a small dataset consisting of 200 BDEs for netural and charged molecules. The dataset is specified in three files:\n",
    "- `molecules.sdf` This file contains all the molecules (both reactants and products) in the bond dissociation reactions. The molecules are specified in SDF format. \n",
    "- `molecule_attributes.yaml` This file contains extra molecular attributes (charges here) for molecules given in `molecules.sdf`. Some molecular attributes can be inferred from its SDF block, and they are overrode by the attributes specified in the `molecule_attributes.yaml` file.  \n",
    "- `reactions.csv` This file list the bond dissociation reations formed by the molecules given in `molecules.sdf`. Each line lists the reactant, products, and BDE of a reaction. The reactant and products are specified by their index in `molecules.sdf`. \n",
    "\n",
    "See [here](./examples/train) for the three files used in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapher \n",
    "\n",
    "BondNet is graph neutral network model that takes atom features (e.g. atom type), bond features (e.g. whether a bond is in a ring), and global features (e.g. total charge) as input. We extract the features for a molecule using a grapher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grapher():\n",
    "    atom_featurizer = AtomFeaturizerMinimum()\n",
    "    bond_featurizer = BondAsNodeFeaturizerMinimum()\n",
    "    \n",
    "    # our example dataset contains molecules of charges -1, 0, and 1\n",
    "    global_featurizer = GlobalFeaturizer(allowed_charges=[-1, 0, 1])\n",
    "\n",
    "    grapher = HeteroMoleculeGraph(atom_featurizer, bond_featurizer, global_featurizer)\n",
    "    \n",
    "    return grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset \n",
    "\n",
    "Let's now read the dataset and featurize the molecules using the above defined grapher. The dataset is split into a training set (80%), validation set (10%), and test set (10%). We will train our model using the training set, stop the training using the validation set, and report error on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [21:11:20] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    }
   ],
   "source": [
    "# seed random number generators \n",
    "seed_torch()\n",
    "\n",
    "mols, attrs, labels = read_input_files(\n",
    "    'examples/train/molecules.sdf', \n",
    "    'examples/train/molecule_attributes.yaml', \n",
    "    'examples/train/reactions.yaml', \n",
    ")\n",
    "dataset = ReactionNetworkDataset(\n",
    "    grapher=get_grapher(),\n",
    "    molecules=mols,\n",
    "    labels=labels,\n",
    "    extra_features=attrs\n",
    ")\n",
    "\n",
    "trainset, valset, testset = train_validation_test_split(dataset, validation=0.1, test=0.1)\n",
    "\n",
    "# we train with a batch size of 100\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=100,shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "We create the BonDNet model by instantiating the `GatedGCNReactionNetwork` class and providing the parameters defining the model structure. \n",
    "- `embedding_size` The size to unify the atom, bond, and global feature length.\n",
    "- `gated_num_layers` Number of graph to graph module to learn molecular representation. \n",
    "- `gated_hidden_size` Hidden layer size in the graph to graph modules. \n",
    "- `gated_activation` Activation function appleid after the hidden layers in the graph to graph modules. \n",
    "- `fc_num_layers` Number of hidden layers of the fully connected network to map reaction feature to the BDE. The reaction feature is obtained as the differece of the features between the products and the reactant. \n",
    "- `fc_hidden_size` Size of the hidden layers. \n",
    "- `fc_activation` Activation function applied after the hidden layers. \n",
    "\n",
    "There are other arguments (e.g. residual connection, dropout ratio, batch norm) that can be specified to fine control the model. See the documentation of the `GatedGCNReactionNetwork` for more information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=24,\n",
    "    gated_num_layers=3,\n",
    "    gated_hidden_size=[64, 64, 64],\n",
    "    gated_activation=\"ReLU\",\n",
    "    fc_num_layers=2,\n",
    "    fc_hidden_size=[128, 64],\n",
    "    fc_activation='ReLU'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model \n",
    "\n",
    "Before going to the main training loop, we define two functions: `train` and `evaluate` that will be used later. \n",
    "\n",
    "The `train` function optimizes the model parameters for an epoch. We note that our target BDEs are centered and then normalized by the standard deviation (done in the `ReactionNetworkDataset`.) So to measure the mean absolute error, we need to multiply the standard deviation back. This is acheived achieved by the `WeightedL1Loss` function passed as `metric_fn`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, model, nodes, data_loader, loss_fn, metric_fn):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    for it, (batched_graph, label) in enumerate(data_loader):\n",
    "        feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "        target = label[\"value\"]\n",
    "        stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "        pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "        pred = pred.view(-1)\n",
    "\n",
    "        loss = loss_fn(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.detach().item()\n",
    "        accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "        count += len(target)\n",
    "    \n",
    "    epoch_loss /= it + 1\n",
    "    accuracy /= count\n",
    "\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate` function computes the mean absolute error for the validation set (or test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, nodes, data_loader, metric_fn):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        count = 0.0\n",
    "\n",
    "        for batched_graph, label in data_loader:\n",
    "            feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "            target = label[\"value\"]\n",
    "            stdev = label[\"scaler_stdev\"]\n",
    "\n",
    "            pred = model(batched_graph, feats, label[\"reaction\"])\n",
    "            pred = pred.view(-1)\n",
    "\n",
    "            accuracy += metric_fn(pred, target, stdev).detach().item()\n",
    "            count += len(target)\n",
    "\n",
    "    return accuracy / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the ingredients to train the model. \n",
    "\n",
    "We optimize the model parameters by minimizing a mean squared error loss function using the `Adam` optimizer with a learning rate of `0.001`. Here we train the model for 20 epochs; save the best performing model that gets the smallest mean absolute error on the validation set; and finally test model performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch     Loss         TrainAcc        ValAcc\n",
      "    0   9.525199e-01   2.600927e+00   1.856763e+00\n",
      "    1   6.184880e-01   2.133040e+00   1.708892e+00\n",
      "    2   4.804114e-01   1.841341e+00   1.465564e+00\n",
      "    3   3.911164e-01   1.719907e+00   1.305253e+00\n",
      "    4   3.467820e-01   1.489159e+00   1.328367e+00\n",
      "    5   3.076128e-01   1.400465e+00   1.341439e+00\n",
      "    6   2.456107e-01   1.300765e+00   1.197294e+00\n",
      "    7   1.980225e-01   1.196393e+00   1.106226e+00\n",
      "    8   1.839220e-01   1.191326e+00   1.060687e+00\n",
      "    9   1.388365e-01   1.059039e+00   1.089829e+00\n",
      "   10   1.406667e-01   1.064811e+00   1.114010e+00\n",
      "   11   1.270391e-01   9.480188e-01   1.078485e+00\n",
      "   12   1.015335e-01   8.797062e-01   1.050378e+00\n",
      "   13   1.063447e-01   8.935841e-01   1.126571e+00\n",
      "   14   9.682498e-02   8.695317e-01   1.176106e+00\n",
      "   15   7.486190e-02   7.605587e-01   1.151517e+00\n",
      "   16   7.939442e-02   7.719594e-01   1.118302e+00\n",
      "   17   6.532137e-02   7.105097e-01   1.018056e+00\n",
      "   18   5.518944e-02   6.295395e-01   1.051672e+00\n",
      "   19   6.019309e-02   6.262228e-01   1.091429e+00\n",
      "TestAcc: 1.648829e+00\n"
     ]
    }
   ],
   "source": [
    "# optimizer, loss function and metric function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = MSELoss(reduction=\"mean\")\n",
    "metric = WeightedL1Loss(reduction=\"sum\")\n",
    "\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "best = 1e10\n",
    "num_epochs = 20\n",
    "\n",
    "# main training loop\n",
    "print(\"# Epoch     Loss         TrainAcc        ValAcc\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # train on training set \n",
    "    loss, train_acc = train( optimizer, model, feature_names, train_loader, loss_func, metric)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    val_acc = evaluate(model, feature_names, val_loader, metric)\n",
    "\n",
    "    # save checkpoint for best performing model \n",
    "    is_best = val_acc < best\n",
    "    if is_best:\n",
    "        best = val_acc\n",
    "        torch.save(model.state_dict(), 'checkpoint.pkl')\n",
    "        \n",
    "    print(\"{:5d}   {:12.6e}   {:12.6e}   {:12.6e}\".format(epoch, loss, train_acc, val_acc))\n",
    "\n",
    "\n",
    "# load best performing model and test it's performance on the test set\n",
    "checkpoint = torch.load(\"checkpoint.pkl\")\n",
    "model.load_state_dict(checkpoint)\n",
    "test_acc = evaluate(model, feature_names, test_loader, metric)\n",
    "\n",
    "print(\"TestAcc: {:12.6e}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
