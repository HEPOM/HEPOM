{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BonDNet \n",
    "\n",
    "In this notebook, we show how to train the BonDNet graph neural network model for bond dissociation energy (BDE) prediction. We only show how to train on CPUs. See [train_bde_distributed.py](./) for a script for training on GPUs (a single GPU or distributed training on multiple GPUs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time, wandb\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "from torchmetrics import R2Score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "#from bondnet.scripts.create_label_file import read_input_files\n",
    "#from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate, \n",
    "    evaluate_classifier, \n",
    "    train, \n",
    "    train_classifier, \n",
    "    load_model, \n",
    "    evaluate_r2, \n",
    "    get_grapher\n",
    ")\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "We work with a small dataset consisting of 200 BDEs for netural and charged molecules. The dataset is specified in three files:\n",
    "- `molecules.sdf` This file contains all the molecules (both reactants and products) in the bond dissociation reactions. The molecules are specified in SDF format. \n",
    "- `molecule_attributes.yaml` This file contains extra molecular attributes (charges here) for molecules given in `molecules.sdf`. Some molecular attributes can be inferred from its SDF block, and they are overrode by the attributes specified in the `molecule_attributes.yaml` file.  \n",
    "- `reactions.csv` This file list the bond dissociation reations formed by the molecules given in `molecules.sdf`. Each line lists the reactant, products, and BDE of a reaction. The reactant and products are specified by their index in `molecules.sdf`. \n",
    "\n",
    "See [here](./examples/train) for the three files used in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapher \n",
    "\n",
    "BondNet is graph neutral network model that takes atom features (e.g. atom type), bond features (e.g. whether a bond is in a ring), and global features (e.g. total charge) as input. We extract the features for a molecule using a grapher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset \n",
    "\n",
    "Let's now read the dataset and featurize the molecules using the above defined grapher. The dataset is split into a training set (80%), validation set (10%), and test set (10%). We will train our model using the training set, stop the training using the validation set, and report error on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: True\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: False\n",
      "filter species? [2, 3]\n",
      "num gpu: 1\n",
      "xyz feeaturizer: False\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 256\n",
      "epochs: 100\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: True\n",
      "transfer_epochs: 100\n",
      "transfer: True\n",
      "loss: False\n",
      "categories: 3\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [128, 64]\n",
      "gated layers: 3\n",
      "gated hidden layers: [64, 64, 64]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "settings_file = './settings.txt'\n",
    "best = 1e10\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "dict_train = parse_settings(settings_file)\n",
    "path_mg_data = \"../../../dataset/mg_dataset/20220826_mpreact_reactions.json\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using bond featurizer w/xyz coords\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 100\n",
      "Program finished in 1.1245083029998568 seconds\n",
      ".............failures.............\n",
      "reactions len: 84\n",
      "valid ind len: 84\n",
      "bond break fail count: \t\t13\n",
      "default fail count: \t\t3\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 84\n",
      "features: 256\n",
      "labels: 84\n",
      "molecules: 256\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 256\n",
      "number of graphs: 256\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if(device == None):\n",
    "    if dict_train[\"on_gpu\"]:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        dict_train[\"gpu\"] = device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dict_train[\"gpu\"] = \"cpu\"\n",
    "else: \n",
    "    dict_train[\"gpu\"] = device\n",
    "    device = torch.device(\"cpu\")\n",
    "path_mg_data = '../dataset/mg_dataset/20220613_reaction_data.json'\n",
    "dataset = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(), \n",
    "    file=path_mg_data, \n",
    "    out_file=\"./\", \n",
    "    target = 'ts', \n",
    "    classifier = False, \n",
    "    classif_categories=5, \n",
    "    debug = True,\n",
    "    filter_species=dict_train[\"filter_species\"],\n",
    "    device =  device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset, testset = train_validation_test_split(dataset, validation=0.2, test=0.2)\n",
    "dataset_loader = DataLoaderReactionNetwork(dataset, batch_size=100,shuffle=True)\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=100,shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)\n",
    "#test_ind = 3\n",
    "#elements = [i['name'] for i in dataset.pandas_df.iloc[test_ind]['reactant_molecule_graph']['molecule']['sites']]\n",
    "#print(elements)\n",
    "#print(len(dataset.molecules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "We create the BonDNet model by instantiating the `GatedGCNReactionNetwork` class and providing the parameters defining the model structure. \n",
    "- `embedding_size` The size to unify the atom, bond, and global feature length.\n",
    "- `gated_num_layers` Number of graph to graph module to learn molecular representation. \n",
    "- `gated_hidden_size` Hidden layer size in the graph to graph modules. \n",
    "- `gated_activation` Activation function appleid after the hidden layers in the graph to graph modules. \n",
    "- `fc_num_layers` Number of hidden layers of the fully connected network to map reaction feature to the BDE. The reaction feature is obtained as the differece of the features between the products and the reactant. \n",
    "- `fc_hidden_size` Size of the hidden layers. \n",
    "- `fc_activation` Activation function applied after the hidden layers. \n",
    "\n",
    "There are other arguments (e.g. residual connection, dropout ratio, batch norm) that can be specified to fine control the model. See the documentation of the `GatedGCNReactionNetwork` for more information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bondnet.model.gated_reaction_network_graph import GatedGCNReactionNetwork\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "#from bondnet.scripts.create_label_file import read_input_files\n",
    "#from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate, \n",
    "    evaluate_classifier, \n",
    "    train, \n",
    "    train_classifier, \n",
    "    load_model, \n",
    "    evaluate_r2, \n",
    "    get_grapher\n",
    ")\n",
    "\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=8,\n",
    "    gated_num_layers=2,\n",
    "    gated_hidden_size=[32, 32],\n",
    "    gated_activation=\"ReLU\",\n",
    "    fc_num_layers=2,\n",
    "    fc_hidden_size=[64, 32],\n",
    "    fc_activation='ReLU'\n",
    ")\n",
    "#print(dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model \n",
    "\n",
    "Before going to the main training loop, we define two functions: `train` and `evaluate` that will be used later. \n",
    "\n",
    "The `train` function optimizes the model parameters for an epoch. We note that our target BDEs are centered and then normalized by the standard deviation (done in the `ReactionNetworkDataset`.) So to measure the mean absolute error, we need to multiply the standard deviation back. This is acheived achieved by the `WeightedL1Loss` function passed as `metric_fn`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the ingredients to train the model. \n",
    "\n",
    "We optimize the model parameters by minimizing a mean squared error loss function using the `Adam` optimizer with a learning rate of `0.001`. Here we train the model for 20 epochs; save the best performing model that gets the smallest mean absolute error on the validation set; and finally test model performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:19<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_train['in_feats'] = dataset.feature_size\n",
    "#dict_train[\"learning_rate\"] = 0.1\n",
    "model, optimizer, optimizer_transfer = load_model(dict_train)\n",
    "\n",
    "for epoch in tqdm(range(dict_train['transfer_epochs'])):\n",
    "    loss_transfer, train_acc_transfer = train(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        optimizer_transfer, \n",
    "        device = dict_train[\"gpu\"]\n",
    "    )\n",
    "    val_acc_transfer = evaluate(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "    )\n",
    "\n",
    "    train_r2 = evaluate_r2(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   2.699188e+00       1.22e-01   6.267557e-01   -0.34   0.89\n",
      "    1   7.060315e+00       1.65e-01   6.558151e-01   -0.43   0.96\n",
      "    2   2.651794e+00       1.34e-01   6.666546e-01   -0.46   0.95\n",
      "    3   2.853068e+00       1.42e-01   6.604475e-01   -0.44   0.95\n",
      "    4   2.967622e+00       1.38e-01   6.486682e-01   -0.40   0.95\n",
      "    5   2.870139e+00       1.37e-01   6.392334e-01   -0.37   0.95\n",
      "    6   2.649525e+00       1.35e-01   6.342085e-01   -0.35   0.96\n",
      "    7   2.374305e+00       1.25e-01   6.330262e-01   -0.35   0.96\n",
      "    8   2.184971e+00       1.12e-01   6.341418e-01   -0.35   0.97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11608/675327251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/model/training_utils.py\u001b[0m in \u001b[0;36mevaluate_r2\u001b[0;34m(model, nodes, data_loader, device)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mnorm_atom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_atom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mnorm_bond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_bond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reaction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mtarget_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/model/gated_reaction_network_graph.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feats, reactions, norm_atom, norm_bond, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# products feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# graph is actually batch graphs, not just a graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol_graph_to_rxn_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# readout layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(dict_train['epochs']):\n",
    "\n",
    "        \n",
    "    loss, train_acc = train(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "    # evaluate on validation set\n",
    "    val_acc = evaluate(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "    val_r2 = evaluate_r2(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "        \n",
    "    train_r2 = evaluate_r2(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}   {:.2f}\".format(\n",
    "            epoch, loss, train_acc, val_acc, val_r2, train_r2\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c205a9eb4435b0aa27aaf0e9c4340d2b9512e0cc8b49dbd290219ad3711c312f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('bondnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
