{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BonDNet \n",
    "\n",
    "In this notebook, we show how to train the BonDNet graph neural network model for bond dissociation energy (BDE) prediction. We only show how to train on CPUs. See [train_bde_distributed.py](./) for a script for training on GPUs (a single GPU or distributed training on multiple GPUs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time, wandb\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "from torchmetrics import R2Score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "#from bondnet.scripts.create_label_file import read_input_files\n",
    "#from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate, \n",
    "    evaluate_classifier, \n",
    "    train, \n",
    "    train_classifier, \n",
    "    load_model, \n",
    "    evaluate_r2, \n",
    "    get_grapher\n",
    ")\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "We work with a small dataset consisting of 200 BDEs for netural and charged molecules. The dataset is specified in three files:\n",
    "- `molecules.sdf` This file contains all the molecules (both reactants and products) in the bond dissociation reactions. The molecules are specified in SDF format. \n",
    "- `molecule_attributes.yaml` This file contains extra molecular attributes (charges here) for molecules given in `molecules.sdf`. Some molecular attributes can be inferred from its SDF block, and they are overrode by the attributes specified in the `molecule_attributes.yaml` file.  \n",
    "- `reactions.csv` This file list the bond dissociation reations formed by the molecules given in `molecules.sdf`. Each line lists the reactant, products, and BDE of a reaction. The reactant and products are specified by their index in `molecules.sdf`. \n",
    "\n",
    "See [here](./examples/train) for the three files used in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapher \n",
    "\n",
    "BondNet is graph neutral network model that takes atom features (e.g. atom type), bond features (e.g. whether a bond is in a ring), and global features (e.g. total charge) as input. We extract the features for a molecule using a grapher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset \n",
    "\n",
    "Let's now read the dataset and featurize the molecules using the above defined grapher. The dataset is split into a training set (80%), validation set (10%), and test set (10%). We will train our model using the training set, stop the training using the validation set, and report error on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the following settings:\n",
      "----------------------------------------\n",
      "Small Dataset?: True\n",
      "restore: True\n",
      "distributed: False\n",
      "on gpu: False\n",
      "filter species? [2, 3]\n",
      "num gpu: 1\n",
      "xyz feeaturizer: False\n",
      "hyperparam save file: ./hyper.pkl\n",
      "dataset state dict: home/santiagovargas/Documents/Dataset/mg/dataset_state_dict.pkl\n",
      "model dir /home/santiagovargas/Documents/Dataset/mg/\n",
      "classifier False\n",
      "batch size: 256\n",
      "epochs: 100\n",
      "lr: 0.000100\n",
      "weight decay: 0.000\n",
      "early_stop: True\n",
      "scheduler: True\n",
      "transfer_epochs: 100\n",
      "transfer: True\n",
      "loss: False\n",
      "categories: 3\n",
      "embedding size: 24\n",
      "fc layers: 2\n",
      "fc hidden layer: [128, 64]\n",
      "gated layers: 3\n",
      "gated hidden layers: [64, 64, 64]\n",
      "num lstm iters: 6\n",
      "num lstm layer: 3\n",
      "gated fc layers: 2\n",
      "fc activation: ReLU\n",
      "fc batch norm: 0\n",
      "fc dropout: 0.00\n",
      "gated activation: ReLU\n",
      "gated dropout: 0.10\n",
      "gated batch norm: True\n",
      "gated graph norm: 0\n",
      "gated resid: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "settings_file = './settings.txt'\n",
    "best = 1e10\n",
    "feature_names = [\"atom\", \"bond\", \"global\"]\n",
    "dict_train = parse_settings(settings_file)\n",
    "path_mg_data = \"../../../dataset/mg_dataset/20220826_mpreact_reactions.json\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using bond featurizer w/xyz coords\n",
      "reading file from: ../dataset/mg_dataset/20220613_reaction_data.json\n",
      "rxn raw len: 100\n",
      "Program finished in 0.7190302229998906 seconds\n",
      ".............failures.............\n",
      "reactions len: 84\n",
      "valid ind len: 84\n",
      "bond break fail count: \t\t13\n",
      "default fail count: \t\t3\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 84\n",
      "features: 256\n",
      "labels: 84\n",
      "molecules: 256\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 256\n",
      "number of graphs: 256\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if(device == None):\n",
    "    if dict_train[\"on_gpu\"]:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        dict_train[\"gpu\"] = device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dict_train[\"gpu\"] = \"cpu\"\n",
    "else: \n",
    "    dict_train[\"gpu\"] = device\n",
    "    device = torch.device(\"cpu\")\n",
    "path_mg_data = '../dataset/mg_dataset/20220613_reaction_data.json'\n",
    "dataset = ReactionNetworkDatasetGraphs(\n",
    "    grapher=get_grapher(), \n",
    "    file=path_mg_data, \n",
    "    out_file=\"./\", \n",
    "    target = 'ts', \n",
    "    classifier = dict_train[\"classifier\"], \n",
    "    classif_categories=5, \n",
    "    debug = True,\n",
    "    filter_species=dict_train[\"filter_species\"],\n",
    "    device =  device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset, testset = train_validation_test_split(dataset, validation=0.2, test=0.2)\n",
    "dataset_loader = DataLoaderReactionNetwork(dataset, batch_size=100,shuffle=True)\n",
    "train_loader = DataLoaderReactionNetwork(trainset, batch_size=100,shuffle=True)\n",
    "val_loader = DataLoaderReactionNetwork(valset, batch_size=len(valset), shuffle=False)\n",
    "test_loader = DataLoaderReactionNetwork(testset, batch_size=len(testset), shuffle=False)\n",
    "#test_ind = 3\n",
    "#elements = [i['name'] for i in dataset.pandas_df.iloc[test_ind]['reactant_molecule_graph']['molecule']['sites']]\n",
    "#print(elements)\n",
    "#print(len(dataset.molecules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "We create the BonDNet model by instantiating the `GatedGCNReactionNetwork` class and providing the parameters defining the model structure. \n",
    "- `embedding_size` The size to unify the atom, bond, and global feature length.\n",
    "- `gated_num_layers` Number of graph to graph module to learn molecular representation. \n",
    "- `gated_hidden_size` Hidden layer size in the graph to graph modules. \n",
    "- `gated_activation` Activation function appleid after the hidden layers in the graph to graph modules. \n",
    "- `fc_num_layers` Number of hidden layers of the fully connected network to map reaction feature to the BDE. The reaction feature is obtained as the differece of the features between the products and the reactant. \n",
    "- `fc_hidden_size` Size of the hidden layers. \n",
    "- `fc_activation` Activation function applied after the hidden layers. \n",
    "\n",
    "There are other arguments (e.g. residual connection, dropout ratio, batch norm) that can be specified to fine control the model. See the documentation of the `GatedGCNReactionNetwork` for more information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork\n",
    "\n",
    "from bondnet.model.metric import EarlyStopping\n",
    "from bondnet.data.dataset import ReactionNetworkDatasetGraphs\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetwork\n",
    "from bondnet.data.dataset import train_validation_test_split\n",
    "#from bondnet.scripts.create_label_file import read_input_files\n",
    "#from bondnet.model.metric import WeightedL1Loss, WeightedMSELoss\n",
    "from bondnet.utils import seed_torch, pickle_dump, parse_settings\n",
    "from bondnet.model.training_utils import (\n",
    "    evaluate, \n",
    "    evaluate_classifier, \n",
    "    train, \n",
    "    train_classifier, \n",
    "    load_model, \n",
    "    evaluate_r2, \n",
    "    get_grapher\n",
    ")\n",
    "\n",
    "\n",
    "model = GatedGCNReactionNetwork(\n",
    "    in_feats=dataset.feature_size,\n",
    "    embedding_size=24,\n",
    "    gated_num_layers=2,\n",
    "    gated_hidden_size=[64, 64, 64],\n",
    "    gated_activation=\"ReLU\",\n",
    "    fc_num_layers=2,\n",
    "    fc_hidden_size=[128, 64],\n",
    "    fc_activation='ReLU'\n",
    ")\n",
    "#print(dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model \n",
    "\n",
    "Before going to the main training loop, we define two functions: `train` and `evaluate` that will be used later. \n",
    "\n",
    "The `train` function optimizes the model parameters for an epoch. We note that our target BDEs are centered and then normalized by the standard deviation (done in the `ReactionNetworkDataset`.) So to measure the mean absolute error, we need to multiply the standard deviation back. This is acheived achieved by the `WeightedL1Loss` function passed as `metric_fn`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the ingredients to train the model. \n",
    "\n",
    "We optimize the model parameters by minimizing a mean squared error loss function using the `Adam` optimizer with a learning rate of `0.001`. Here we train the model for 20 epochs; save the best performing model that gets the smallest mean absolute error on the validation set; and finally test model performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_train['in_feats'] = dataset.feature_size\n",
    "dict_train[\"learning_rate\"] = 0.1\n",
    "model, optimizer, optimizer_transfer = load_model(dict_train)\n",
    "\n",
    "for epoch in tqdm(range(dict_train['transfer_epochs'])):\n",
    "    loss_transfer, train_acc_transfer = train(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        optimizer_transfer, \n",
    "        device = dict_train[\"gpu\"]\n",
    "    )\n",
    "    val_acc_transfer = evaluate(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1.638583e+00       1.11e-01   2.615526e+00   -77.48   0.97\n",
      "    1   1.642438e+00       1.15e-01   2.617258e+00   -77.03   0.97\n",
      "    2   1.556149e+00       1.11e-01   2.613293e+00   -76.78   0.97\n",
      "    3   1.484051e+00       1.06e-01   2.618382e+00   -76.32   0.98\n",
      "    4   1.404751e+00       1.02e-01   2.599646e+00   -76.03   0.98\n",
      "    5   1.387124e+00       1.04e-01   2.606691e+00   -76.04   0.98\n",
      "    6   1.283745e+00       9.57e-02   2.623361e+00   -75.66   0.98\n",
      "    7   1.273531e+00       9.62e-02   2.603083e+00   -75.04   0.98\n",
      "    8   1.203421e+00       9.14e-02   2.586739e+00   -74.72   0.98\n",
      "    9   1.212638e+00       9.51e-02   2.608254e+00   -74.77   0.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11608/3102461399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/model/training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, nodes, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# here is the actual optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(dict_train['epochs']):\n",
    "\n",
    "        \n",
    "    loss, train_acc = train(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "    # evaluate on validation set\n",
    "    val_acc = evaluate(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "    val_r2 = evaluate_r2(\n",
    "        model, \n",
    "        feature_names, \n",
    "        val_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "    train_r2 = evaluate_r2(\n",
    "        model, \n",
    "        feature_names, \n",
    "        train_loader, \n",
    "        device = dict_train[\"gpu\"]\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"{:5d}   {:12.6e}   {:12.2e}   {:12.6e}   {:.2f}   {:.2f}\".format(\n",
    "            epoch, loss, train_acc, val_acc, val_r2, train_r2\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c205a9eb4435b0aa27aaf0e9c4340d2b9512e0cc8b49dbd290219ad3711c312f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('bondnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
