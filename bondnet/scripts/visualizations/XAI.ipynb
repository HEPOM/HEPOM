{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook on Getting Explanations from a trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::RESTORING MODEL FROM EXISTING FILE:::\n",
      "NB: using GatedGCNConv\n",
      ":::MODEL LOADED:::\n"
     ]
    }
   ],
   "source": [
    "from bondnet.model.training_utils import (\n",
    "    get_grapher,\n",
    "    load_model_lightning,\n",
    ")\n",
    "from bondnet.data.utils import mol_graph_to_rxn_graph\n",
    "import dgl\n",
    "\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"restore\": True,\n",
    "        \"restore_path\": \"../../../tests/model/test_save_load/test.ckpt\",  # path to ckpt\n",
    "    }\n",
    "}\n",
    "\n",
    "model_restart = load_model_lightning(config[\"model\"], load_dir=\"./test_save_load/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_list None\n",
      "reading file from: ../../../tests/data/testdata/barrier_100.json\n",
      "rxn raw len: 100\n",
      "Program finished in 0.7386780519991589 seconds\n",
      ".............failures.............\n",
      "reactions len: 100\n",
      "valid ind len: 100\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t0\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 100\n",
      "features: 240\n",
      "labels: 100\n",
      "molecules: 240\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 240\n",
      "number of graphs: 240\n"
     ]
    }
   ],
   "source": [
    "from bondnet.data.datamodule import BondNetLightningDataModule\n",
    "\n",
    "dataset_loc = \"../../../tests/data/testdata/barrier_100.json\"\n",
    "\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": dataset_loc,\n",
    "        \"target_var\": \"dG_barrier\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"extra_features\": [\"bond_length\"],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.0,\n",
    "        \"test_size\": 0.85,\n",
    "        \"batch_size\": 1,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "dm = BondNetLightningDataModule(config)\n",
    "feat_size, feat_name = dm.prepare_data()\n",
    "dm.setup(stage=\"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['615986114661599']\n",
      "['665885584266589']\n",
      "['682605097168261']\n",
      "['634165265063417']\n",
      "['663936101266392']\n",
      "['635425371763543']\n",
      "['643725370764373']\n",
      "['637705095163771']\n",
      "['138428113934138427']\n",
      "['142070117901142069']\n",
      "['668506082066851']\n",
      "['641325061864133']\n",
      "['688245084668825']\n",
      "['628985724862899']\n",
      "['142259118367142260']\n"
     ]
    }
   ],
   "source": [
    "embedding_list = []\n",
    "\n",
    "nodes = [\"atom\", \"bond\", \"global\"]\n",
    "embedding_size = model_restart.hparams.embedding_size\n",
    "batch_size = len(dm.train_ds)\n",
    "\n",
    "direct_concat_name = model_restart.hparams.set2set_ntypes_direct\n",
    "gat_out = model_restart.hparams.gated_hidden_size[-1]\n",
    "readout_out_size = gat_out * 2 + gat_out * 2\n",
    "readout_out_size += gat_out * len(direct_concat_name)\n",
    "targets = []\n",
    "for it, (batched_graph, label) in enumerate(dm.train_dataloader()):\n",
    "    feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "\n",
    "    target = label[\"value\"].view(-1)\n",
    "\n",
    "    norm_atom = label[\"norm_atom\"]\n",
    "    norm_bond = label[\"norm_bond\"]\n",
    "    stdev = label[\"scaler_stdev\"]\n",
    "    reactions = label[\"reaction\"]\n",
    "    targets.append(target)\n",
    "    embeddings = model_restart.feature_before_fc(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "    )\n",
    "\n",
    "    graph_rxn, feats_rxn = mol_graph_to_rxn_graph(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        reverse=False,\n",
    "    )\n",
    "    # print(reactions)\n",
    "    print(reactions[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5888])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_428435/3402756425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnorm_atom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_atom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnorm_bond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_bond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/model/gated_reaction_network_lightning.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feats, reactions, norm_atom, norm_bond, reverse)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         )\n\u001b[1;32m   2435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256])"
     ]
    }
   ],
   "source": [
    "pred = model_restart(\n",
    "    graph=batched_graph,\n",
    "    feats=feats,\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_428435/2818314081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_restart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred_loss = model_restart.loss(pred.view(-1), target)\n",
    "pred_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bond (20, 20)\n",
      "atom (20, 20)\n",
      "global (1, 1)\n",
      "bond (20, 20)\n",
      "atom (20, 20)\n",
      "global (1, 1)\n",
      "bond (20, 20)\n",
      "atom (20, 20)\n",
      "global (1, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from bondnet.data.utils import mol_graph_to_rxn_graph\n",
    "\n",
    "\n",
    "def _split_batched_output(graph, value, n_type=\"bond\"):\n",
    "    \"\"\"\n",
    "    Split a tensor into `num_graphs` chunks, the size of each chunk equals the\n",
    "    number of bonds in the graph.\n",
    "\n",
    "    Returns:\n",
    "        list of tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    nbonds = tuple(graph.batch_num_nodes(n_type).tolist())\n",
    "    print(n_type, nbonds)\n",
    "    split_tensor = torch.split(value, nbonds)\n",
    "    # print(len(split_tensor))\n",
    "    return split_tensor\n",
    "\n",
    "\n",
    "def feature_at_each_layer(model, graph, feats, reactions, norm_atom, norm_bond):\n",
    "    \"\"\"\n",
    "    Get the features at each layer before the final fully-connected layer.\n",
    "\n",
    "    This is used for feature visualization to see how the model learns.\n",
    "\n",
    "    Returns:\n",
    "        dict: (layer_idx, feats), each feats is a list of\n",
    "    \"\"\"\n",
    "\n",
    "    layer_idx = 0\n",
    "\n",
    "    bond_feats = {}\n",
    "    atom_feats = {}\n",
    "    global_feats = {}\n",
    "\n",
    "    feats = model.embedding(feats)\n",
    "    bond_feats[layer_idx] = _split_batched_output(graph, feats[\"bond\"], \"bond\")\n",
    "    atom_feats[layer_idx] = _split_batched_output(graph, feats[\"atom\"], \"atom\")\n",
    "    global_feats[layer_idx] = _split_batched_output(graph, feats[\"global\"], \"global\")\n",
    "\n",
    "    layer_idx += 1\n",
    "\n",
    "    # gated layer\n",
    "    for layer in model.gated_layers:\n",
    "        feats = layer(graph, feats, norm_atom, norm_bond)\n",
    "\n",
    "        # store bond feature of each molecule\n",
    "        bond_feats[layer_idx] = _split_batched_output(graph, feats[\"bond\"], \"bond\")\n",
    "\n",
    "        atom_feats[layer_idx] = _split_batched_output(graph, feats[\"atom\"], \"atom\")\n",
    "\n",
    "        global_feats[layer_idx] = _split_batched_output(\n",
    "            graph, feats[\"global\"], \"global\"\n",
    "        )\n",
    "\n",
    "        layer_idx += 1\n",
    "\n",
    "    return bond_feats, atom_feats, global_feats\n",
    "\n",
    "\n",
    "# outputs are reactant then product feats for each node type\n",
    "\n",
    "bond_feats, atoms_feats, global_feats = feature_at_each_layer(\n",
    "    model=model_restart,\n",
    "    graph=batched_graph,  # for a given set of graph feats\n",
    "    feats=feats,  # and a given set of feats\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    ")\n",
    "unbatched_graph = dgl.unbatch(batched_graph)\n",
    "# unbatched_graph = dgl.unbatch(batched_graph)\n",
    "# print(len(unbatched_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_person(features):\n",
    "    \"\"\"\n",
    "    Compute the Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "        ntype (str): the node type of the graph where the features are stored, e.g.\n",
    "            `atom` and `bond`.\n",
    "        exclude (list, optional): indices of features to ignore. This is useful to\n",
    "            exclude features with 0 stdandard deviation. If `None`, nothing to\n",
    "            exclude. Defaults to None.\n",
    "    Returns:\n",
    "        2D array: correlation between features\n",
    "    \"\"\"\n",
    "\n",
    "    features = features.detach().numpy()\n",
    "    # remove features with 0 standard deviation\n",
    "    remove_idx = []\n",
    "    for i in range(features.shape[1]):\n",
    "        if np.std(features[:, i]) == 0:\n",
    "            remove_idx.append(i)\n",
    "    # remove features on remove_idx\n",
    "    features = np.delete(features, remove_idx, axis=1)\n",
    "    corr = np.corrcoef(features)\n",
    "    return corr\n",
    "\n",
    "\n",
    "compute_corr = compute_person(atoms_feats[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bondnet.data.reaction_network.ReactionInNetwork at 0x7f4be6b6e310>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12203892800122039\n",
    "reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bondnet.data.reaction_network.ReactionInNetwork"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reactions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193] [194]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    reactions[0].init_reactants,\n",
    "    reactions[0].init_products,\n",
    ")\n",
    "\n",
    "\n",
    "def mols_from_reaction(reactions, ids=0):\n",
    "    product_wrapper = []\n",
    "    reactant_wrapper = []\n",
    "\n",
    "    for i in reactions[ids].init_reactants:\n",
    "        reactant_wrapper.append(\n",
    "            dm.train_ds.dataset.reaction_network.molecule_wrapper[i]\n",
    "        )\n",
    "        #print(i, dm.train_ds.dataset.reaction_network.molecule_wrapper[i].id)\n",
    "\n",
    "    for i in reactions[ids].init_products:\n",
    "        # dm.train_ds.dataset.reaction_network.molecule_wrapper[i]\n",
    "        # print(i)\n",
    "        product_wrapper.append(dm.train_ds.dataset.reaction_network.molecule_wrapper[i])\n",
    "        #print(i, dm.train_ds.dataset.reaction_network.molecule_wrapper[i].id)\n",
    "\n",
    "    pmg_reactants = [i.pymatgen_mol for i in reactant_wrapper]\n",
    "    pmg_products = [i.pymatgen_mol for i in product_wrapper]\n",
    "    return pmg_reactants, pmg_products\n",
    "\n",
    "\n",
    "pmg_reactants, pmg_products = mols_from_reaction(reactions, ids=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "193 142260\n",
      "194 142259\n"
     ]
    }
   ],
   "source": [
    "pmg_reactants, pmg_products = mols_from_reaction(id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Molecule Summary\n",
       " Site: C (-1.3928, 1.7495, 0.5385)\n",
       " Site: C (-0.7083, 0.4085, 0.5990)\n",
       " Site: N (-0.7252, -0.4562, -0.5672)\n",
       " Site: C (-1.0805, -1.8517, -0.4087)\n",
       " Site: C (0.5643, 0.0533, -0.1016)\n",
       " Site: C (1.5414, -0.8777, 0.5889)\n",
       " Site: C (1.2417, 1.0365, -1.0330)\n",
       " Site: H (-1.0024, 2.4149, 1.3227)\n",
       " Site: H (-1.2460, 2.2370, -0.4341)\n",
       " Site: H (-2.4748, 1.6341, 0.7014)\n",
       " Site: H (-0.8445, -0.1098, 1.5583)\n",
       " Site: H (-0.5708, -2.4522, -1.1757)\n",
       " Site: H (-0.8307, -2.2708, 0.5822)\n",
       " Site: H (-2.1647, -1.9631, -0.5542)\n",
       " Site: H (2.3264, -0.2862, 1.0813)\n",
       " Site: H (1.0668, -1.5035, 1.3542)\n",
       " Site: H (2.0304, -1.5360, -0.1458)\n",
       " Site: H (0.5124, 1.6340, -1.5929)\n",
       " Site: H (1.8679, 0.4973, -1.7601)\n",
       " Site: H (1.8934, 1.7193, -0.4672)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmg_reactants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7f4be7719690>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot pymatgen mol\n",
    "from ase.visualize.plot import plot_atoms\n",
    "from ase.visualize import view\n",
    "from io import StringIO\n",
    "from ase.io import read\n",
    "\n",
    "xyz_string = pmg_reactants[0].to(\"xyz\")\n",
    "sdf_string = pmg_reactants[0].to(\"sdf\")\n",
    "molblock = pmg_reactants[0].to(\"mol\")\n",
    "f = StringIO(xyz_string)\n",
    "atoms = read(f, format=\"xyz\")\n",
    "\n",
    "# view(atoms, rotation='10x,20y,30z')\n",
    "view(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n OpenBabel11102313483D\\n\\n 20 20  0  0  1  0  0  0  0  0999 V2000\\n   -1.3928    1.7495    0.5385 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.7083    0.4085    0.5990 C   0  0  1  0  0  0  0  0  0  0  0  0\\n   -0.7252   -0.4562   -0.5672 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.0805   -1.8517   -0.4087 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.5643    0.0533   -0.1016 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.5414   -0.8777    0.5889 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.2417    1.0365   -1.0330 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.0024    2.4149    1.3227 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.2460    2.2370   -0.4341 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.4748    1.6341    0.7014 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.8445   -0.1098    1.5583 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.5708   -2.4522   -1.1757 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.8307   -2.2708    0.5822 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.1647   -1.9631   -0.5542 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3264   -0.2862    1.0813 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.0668   -1.5035    1.3542 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.0304   -1.5360   -0.1458 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.5124    1.6340   -1.5929 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.8679    0.4973   -1.7601 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.8934    1.7193   -0.4672 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0  0  0  0\\n  1 10  1  0  0  0  0\\n  1  8  1  0  0  0  0\\n  2 11  1  1  0  0  0\\n  3  4  1  0  0  0  0\\n  3  5  1  0  0  0  0\\n  3  2  1  0  0  0  0\\n  4 13  1  0  0  0  0\\n  5  6  1  0  0  0  0\\n  5  2  1  0  0  0  0\\n  6 15  1  0  0  0  0\\n  6 16  1  0  0  0  0\\n  7 20  1  0  0  0  0\\n  7  5  1  0  0  0  0\\n  9  1  1  0  0  0  0\\n 12  4  1  0  0  0  0\\n 14  4  1  0  0  0  0\\n 17  6  1  0  0  0  0\\n 18  7  1  0  0  0  0\\n 19  7  1  0  0  0  0\\nM  END\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert xyz to mol in rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "\n",
    "\n",
    "mol = Chem.MolFromMolBlock(molblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, atom in enumerate(mol.GetAtoms()):\n",
    "    corr_i = compute_corr[0][ind]\n",
    "    atom.SetProp(\"atomNote\", \"corr: {:.2f}\".format(corr_i))\n",
    "\n",
    "# show hhydrogens in plot\n",
    "# mol = Chem.AddHs(mol)\n",
    "size = (240, 240)\n",
    "fig = Draw.ShowMol(\n",
    "    mol, \n",
    "    size=size, \n",
    "    kekulize=False, \n",
    "    wedgeBonds=False, \n",
    "    showAtomNumbers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_at_each_layer(model, graph, feats, reactions, norm_atom, norm_bond, target):\n",
    "    \"\"\"\n",
    "    Get the features at each layer before the final fully-connected layer.\n",
    "\n",
    "    This is used for feature visualization to see how the model learns.\n",
    "\n",
    "    Returns:\n",
    "        dict: (layer_idx, feats), each feats is a list of\n",
    "    \"\"\"\n",
    "\n",
    "    layer_idx = 0\n",
    "    bond_grads = {}\n",
    "    atom_grads = {}\n",
    "    global_grads = {}\n",
    "\n",
    "    pred = model(\n",
    "        graph=graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "    )\n",
    "    dict_grads = {\"embedding\": {}, \"gated\": {}}\n",
    "\n",
    "    model.loss(pred.view(-1), target).backward()\n",
    "    linear_index = 0\n",
    "    dict_grads[\"embedding\"][\"atom\"] = model.embedding.linears[\"atom\"].weight.grad\n",
    "    dict_grads[\"embedding\"][\"bond\"] = model.embedding.linears[\"bond\"].weight.grad\n",
    "    dict_grads[\"embedding\"][\"global\"] = model.embedding.linears[\"global\"].weight.grad\n",
    "\n",
    "    # gated layer\n",
    "    for layer in model.gated_layers:\n",
    "        for name, param in layer.A.named_parameters():\n",
    "            dict_grads[\"gated\"][\"A_\" + name] = param.grad\n",
    "        for name, param in layer.B.named_parameters():\n",
    "            dict_grads[\"gated\"][\"B_\" + name] = param.grad\n",
    "        for name, param in layer.C.named_parameters():\n",
    "            dict_grads[\"gated\"][\"C_\" + name] = param.grad\n",
    "        for name, param in layer.D.named_parameters():\n",
    "            dict_grads[\"gated\"][\"D_\" + name] = param.grad\n",
    "        for name, param in layer.E.named_parameters():\n",
    "            dict_grads[\"gated\"][\"E_\" + name] = param.grad\n",
    "        for name, param in layer.F.named_parameters():\n",
    "            dict_grads[\"gated\"][\"F_\" + name] = param.grad\n",
    "        for name, param in layer.G.named_parameters():\n",
    "            dict_grads[\"gated\"][\"G_\" + name] = param.grad\n",
    "        for name, param in layer.H.named_parameters():\n",
    "            dict_grads[\"gated\"][\"H_\" + name] = param.grad\n",
    "        for name, param in layer.I.named_parameters():\n",
    "            dict_grads[\"gated\"][\"I_\" + name] = param.grad\n",
    "\n",
    "    return dict_grads\n",
    "\n",
    "\n",
    "dict_grads = grad_at_each_layer(\n",
    "    model=model_restart,\n",
    "    graph=batched_graph,\n",
    "    feats=feats,\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    "    target=target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# this operates at the node level???\n",
    "# this is just what nodes are activated\n",
    "def saliency_map(input_grads):\n",
    "    node_saliency_map = []\n",
    "    for n in range(input_grads.shape[0]):  # nth node\n",
    "        node_grads = input_grads[n, :]\n",
    "        node_saliency = torch.norm(F.relu(node_grads)).item()\n",
    "        node_saliency_map.append(node_saliency)\n",
    "    return node_saliency_map\n",
    "\n",
    "\n",
    "def grad_cam(final_conv_acts, final_conv_grads):\n",
    "    # print('grad_cam')\n",
    "    node_heat_map = []\n",
    "    alphas = torch.mean(\n",
    "        final_conv_grads, axis=0\n",
    "    )  # mean gradient for each feature (512x1)\n",
    "    for n in range(final_conv_acts.shape[0]):  # nth node\n",
    "        node_heat = F.relu(alphas @ final_conv_acts[n]).item()\n",
    "        node_heat_map.append(node_heat)\n",
    "    return node_heat_map\n",
    "\n",
    "\n",
    "def ugrad_cam(n_atoms, final_conv_acts, final_conv_grads):\n",
    "    # print('new_grad_cam')\n",
    "    node_heat_map = []\n",
    "    alphas = torch.mean(\n",
    "        final_conv_grads, axis=0\n",
    "    )  # mean gradient for each feature (512x1)\n",
    "    for n in range(final_conv_acts.shape[0]):  # nth node\n",
    "        node_heat = (alphas @ final_conv_acts[n]).item()\n",
    "        node_heat_map.append(node_heat)\n",
    "\n",
    "    node_heat_map = np.array(node_heat_map[:n_atoms]).reshape(-1, 1)\n",
    "    pos_node_heat_map = (\n",
    "        MinMaxScaler(feature_range=(0, 1))\n",
    "        .fit_transform(node_heat_map * (node_heat_map >= 0))\n",
    "        .reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    neg_node_heat_map = (\n",
    "        MinMaxScaler(feature_range=(-1, 0))\n",
    "        .fit_transform(node_heat_map * (node_heat_map < 0))\n",
    "        .reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return pos_node_heat_map + neg_node_heat_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
