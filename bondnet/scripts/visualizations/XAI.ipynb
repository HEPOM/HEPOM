{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook on Getting Explanations from a trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::RESTORING MODEL FROM EXISTING FILE:::\n",
      "NB: using GatedGCNConv\n",
      ":::MODEL LOADED:::\n"
     ]
    }
   ],
   "source": [
    "from bondnet.model.training_utils import (\n",
    "    get_grapher,\n",
    "    load_model_lightning,\n",
    ")\n",
    "from bondnet.data.utils import mol_graph_to_rxn_graph\n",
    "import dgl\n",
    "\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"restore\": True,\n",
    "        \"restore_path\": \"../../../tests/model/test_save_load/test.ckpt\",  # path to ckpt\n",
    "    }\n",
    "}\n",
    "\n",
    "model_restart = load_model_lightning(config[\"model\"], load_dir=\"./test_save_load/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file from: ../../../tests/data/testdata/barrier_100.json\n",
      "rxn raw len: 100\n",
      "Program finished in 0.794138582990854 seconds\n",
      ".............failures.............\n",
      "reactions len: 100\n",
      "valid ind len: 100\n",
      "bond break fail count: \t\t0\n",
      "default fail count: \t\t0\n",
      "sdf map fail count: \t\t0\n",
      "product bond fail count: \t0\n",
      "about to group and organize\n",
      "number of grouped reactions: 100\n",
      "features: 240\n",
      "labels: 100\n",
      "molecules: 240\n",
      "constructing graphs & features....\n",
      "number of graphs valid: 240\n",
      "number of graphs: 240\n"
     ]
    }
   ],
   "source": [
    "from bondnet.data.datamodule import BondNetLightningDataModule\n",
    "\n",
    "dataset_loc = \"../../../tests/data/testdata/barrier_100.json\"\n",
    "\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": dataset_loc,\n",
    "        \"target_var\": \"dG_barrier\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"extra_features\": [\"bond_length\"],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.0,\n",
    "        \"test_size\": 0.85,\n",
    "        \"batch_size\": 1,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "dm = BondNetLightningDataModule(config)\n",
    "feat_size, feat_name = dm.prepare_data()\n",
    "dm.setup(stage=\"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10527514179105274']\n",
      "['637705095163771']\n",
      "['674486061767449']\n",
      "['12203892800122039']\n",
      "['13334949506133350']\n",
      "['139105113297139106']\n",
      "['638184940563819']\n",
      "['142070117901142069']\n",
      "['141512115712141511']\n",
      "['127302109520127303']\n",
      "['645255652164524']\n",
      "['142259118367142260']\n",
      "['12535392445125355']\n",
      "['317061459631705']\n",
      "['668205595666821']\n"
     ]
    }
   ],
   "source": [
    "embedding_list = []\n",
    "\n",
    "nodes = [\"atom\", \"bond\", \"global\"]\n",
    "embedding_size = model_restart.hparams.embedding_size\n",
    "batch_size = len(dm.train_ds)\n",
    "\n",
    "direct_concat_name = model_restart.hparams.set2set_ntypes_direct\n",
    "gat_out = model_restart.hparams.gated_hidden_size[-1]\n",
    "readout_out_size = gat_out * 2 + gat_out * 2\n",
    "readout_out_size += gat_out * len(direct_concat_name)\n",
    "targets = []\n",
    "for it, (batched_graph, label) in enumerate(dm.train_dataloader()):\n",
    "    feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "\n",
    "    target = label[\"value\"].view(-1)\n",
    "\n",
    "    norm_atom = label[\"norm_atom\"]\n",
    "    norm_bond = label[\"norm_bond\"]\n",
    "    stdev = label[\"scaler_stdev\"]\n",
    "    reactions = label[\"reaction\"]\n",
    "    targets.append(target)\n",
    "    embeddings = model_restart.feature_before_fc(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "    )\n",
    "\n",
    "    graph_rxn, feats_rxn = mol_graph_to_rxn_graph(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        reverse=False,\n",
    "    )\n",
    "    # print(reactions)\n",
    "    print(reactions[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6612])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160643/3402756425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnorm_atom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_atom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnorm_bond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_bond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/bondnet/bondnet/model/gated_reaction_network_lightning.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feats, reactions, norm_atom, norm_bond, reverse)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         )\n\u001b[1;32m   2435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256])"
     ]
    }
   ],
   "source": [
    "pred = model_restart(\n",
    "    graph=batched_graph,\n",
    "    feats=feats,\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Predictions and targets are expected to have the same shape, but got torch.Size([3]) and torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160643/2818314081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_restart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m                             \u001b[0;34m\" device corresponds to the device of the input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                         ) from err\n\u001b[0;32m--> 399\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_on_cpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/regression/mse.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"\"\"Update state with predictions and targets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msum_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mean_squared_error_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_squared_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/functional/regression/mse.py\u001b[0m in \u001b[0;36m_mean_squared_error_update\u001b[0;34m(preds, target)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGround\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0m_check_same_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msum_squared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_check_same_shape\u001b[0;34m(preds, target)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;34mf\"Predictions and targets are expected to have the same shape, but got {preds.shape} and {target.shape}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Predictions and targets are expected to have the same shape, but got torch.Size([3]) and torch.Size([1])."
     ]
    }
   ],
   "source": [
    "pred_loss = model_restart.loss(pred.view(-1), target)\n",
    "pred_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bond (10, 10)\n",
      "atom (10, 10)\n",
      "global (1, 1)\n",
      "bond (10, 10)\n",
      "atom (10, 10)\n",
      "global (1, 1)\n",
      "bond (10, 10)\n",
      "atom (10, 10)\n",
      "global (1, 1)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from bondnet.data.utils import mol_graph_to_rxn_graph\n",
    "\n",
    "\n",
    "def _split_batched_output(graph, value, n_type=\"bond\"):\n",
    "    \"\"\"\n",
    "    Split a tensor into `num_graphs` chunks, the size of each chunk equals the\n",
    "    number of bonds in the graph.\n",
    "\n",
    "    Returns:\n",
    "        list of tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    nbonds = tuple(graph.batch_num_nodes(n_type).tolist())\n",
    "    print(n_type, nbonds)\n",
    "    split_tensor = torch.split(value, nbonds)\n",
    "    # print(len(split_tensor))\n",
    "    return split_tensor\n",
    "\n",
    "\n",
    "def feature_at_each_layer(model, graph, feats, reactions, norm_atom, norm_bond):\n",
    "    \"\"\"\n",
    "    Get the features at each layer before the final fully-connected layer.\n",
    "\n",
    "    This is used for feature visualization to see how the model learns.\n",
    "\n",
    "    Returns:\n",
    "        dict: (layer_idx, feats), each feats is a list of\n",
    "    \"\"\"\n",
    "\n",
    "    layer_idx = 0\n",
    "\n",
    "    bond_feats = {}\n",
    "    atom_feats = {}\n",
    "    global_feats = {}\n",
    "\n",
    "    feats = model.embedding(feats)\n",
    "    bond_feats[layer_idx] = _split_batched_output(graph, feats[\"bond\"], \"bond\")\n",
    "    atom_feats[layer_idx] = _split_batched_output(graph, feats[\"atom\"], \"atom\")\n",
    "    global_feats[layer_idx] = _split_batched_output(graph, feats[\"global\"], \"global\")\n",
    "\n",
    "    layer_idx += 1\n",
    "\n",
    "    # gated layer\n",
    "    for layer in model.gated_layers:\n",
    "        feats = layer(graph, feats, norm_atom, norm_bond)\n",
    "\n",
    "        # store bond feature of each molecule\n",
    "        bond_feats[layer_idx] = _split_batched_output(graph, feats[\"bond\"], \"bond\")\n",
    "\n",
    "        atom_feats[layer_idx] = _split_batched_output(graph, feats[\"atom\"], \"atom\")\n",
    "\n",
    "        global_feats[layer_idx] = _split_batched_output(\n",
    "            graph, feats[\"global\"], \"global\"\n",
    "        )\n",
    "\n",
    "        layer_idx += 1\n",
    "\n",
    "    return bond_feats, atom_feats, global_feats\n",
    "\n",
    "\n",
    "# outputs are reactant then product feats for each node type\n",
    "\n",
    "bond_feats, atoms_feats, global_feats = feature_at_each_layer(\n",
    "    model=model_restart,\n",
    "    graph=batched_graph,  # for a given set of graph feats\n",
    "    feats=feats,  # and a given set of feats\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    ")\n",
    "unbatched_graph = dgl.unbatch(batched_graph)\n",
    "# unbatched_graph = dgl.unbatch(batched_graph)\n",
    "# print(len(unbatched_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_person(features):\n",
    "    \"\"\"\n",
    "    Compute the Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "        ntype (str): the node type of the graph where the features are stored, e.g.\n",
    "            `atom` and `bond`.\n",
    "        exclude (list, optional): indices of features to ignore. This is useful to\n",
    "            exclude features with 0 stdandard deviation. If `None`, nothing to\n",
    "            exclude. Defaults to None.\n",
    "    Returns:\n",
    "        2D array: correlation between features\n",
    "    \"\"\"\n",
    "\n",
    "    features = features.detach().numpy()\n",
    "    # remove features with 0 standard deviation\n",
    "    remove_idx = []\n",
    "    for i in range(features.shape[1]):\n",
    "        if np.std(features[:, i]) == 0:\n",
    "            remove_idx.append(i)\n",
    "    # remove features on remove_idx\n",
    "    features = np.delete(features, remove_idx, axis=1)\n",
    "    corr = np.corrcoef(features)\n",
    "    return corr\n",
    "\n",
    "\n",
    "compute_corr = compute_person(atoms_feats[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['668205595666821']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12203892800122039\n",
    "reactions[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bondnet.data.reaction_network.ReactionInNetwork"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reactions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23] [24]\n",
      "23\n",
      "23 66821\n",
      "24 66820\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    reactions[0].init_reactants,\n",
    "    reactions[0].init_products,\n",
    ")\n",
    "\n",
    "\n",
    "def mols_from_reaction(id=0):\n",
    "    product_wrapper = []\n",
    "    reactant_wrapper = []\n",
    "\n",
    "    for i in reactions[id].init_reactants:\n",
    "        print(i)\n",
    "\n",
    "        reactant_wrapper.append(\n",
    "            dm.train_ds.dataset.reaction_network.molecule_wrapper[i]\n",
    "        )\n",
    "        print(i, dm.train_ds.dataset.reaction_network.molecule_wrapper[i].id)\n",
    "\n",
    "    for i in reactions[id].init_products:\n",
    "        # dm.train_ds.dataset.reaction_network.molecule_wrapper[i]\n",
    "        # print(i)\n",
    "        product_wrapper.append(dm.train_ds.dataset.reaction_network.molecule_wrapper[i])\n",
    "\n",
    "        print(i, dm.train_ds.dataset.reaction_network.molecule_wrapper[i].id)\n",
    "\n",
    "    pmg_reactants = [i.pymatgen_mol for i in reactant_wrapper]\n",
    "    pmg_products = [i.pymatgen_mol for i in product_wrapper]\n",
    "    return pmg_reactants, pmg_products\n",
    "\n",
    "\n",
    "pmg_reactants, pmg_products = mols_from_reaction(id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23 66821\n",
      "24 66820\n"
     ]
    }
   ],
   "source": [
    "pmg_reactants, pmg_products = mols_from_reaction(id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Molecule Summary\n",
       " Site: N (1.7704, -0.3109, 0.0006)\n",
       " Site: C (0.4056, -0.1228, 0.0414)\n",
       " Site: N (-0.4637, -1.1234, -0.0685)\n",
       " Site: N (-1.6480, -0.5259, -0.0411)\n",
       " Site: N (-1.6232, 0.7754, 0.0793)\n",
       " Site: C (-0.3303, 1.0821, 0.1339)\n",
       " Site: H (2.3172, 0.4137, 0.4460)\n",
       " Site: H (2.0791, -1.2401, 0.2566)\n",
       " Site: H (-2.5130, -1.0481, -0.1018)\n",
       " Site: H (0.0178, 2.1058, 0.2341)]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmg_reactants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7f82700fa0d0>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot pymatgen mol\n",
    "from ase.visualize.plot import plot_atoms\n",
    "from ase.visualize import view\n",
    "from io import StringIO\n",
    "from ase.io import read\n",
    "\n",
    "xyz_string = pmg_products[0].to(\"xyz\")\n",
    "sdf_string = pmg_products[0].to(\"sdf\")\n",
    "molblock = pmg_products[0].to(\"mol\")\n",
    "f = StringIO(xyz_string)\n",
    "atoms = read(f, format=\"xyz\")\n",
    "\n",
    "# view(atoms, rotation='10x,20y,30z')\n",
    "view(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n OpenBabel09072312213D\\n\\n 10 10  0  0  0  0  0  0  0  0999 V2000\\n    1.7693   -0.3176    0.0764 N   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4058   -0.1216    0.0285 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.4637   -1.1236   -0.0667 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.6482   -0.5274   -0.0237 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.6234    0.7745    0.0892 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.3302    1.0825    0.1286 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3275    0.4727   -0.2170 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.0881   -1.1880   -0.3295 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.5133   -1.0500   -0.0801 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.0181    2.1070    0.2213 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  2  1  1  0  0  0  0\\n  2  6  1  0  0  0  0\\n  3  4  1  0  0  0  0\\n  3  2  2  0  0  0  0\\n  4  5  1  0  0  0  0\\n  5  6  2  0  0  0  0\\n  6 10  1  0  0  0  0\\n  7  1  1  0  0  0  0\\n  8  1  1  0  0  0  0\\n  9  4  1  0  0  0  0\\nM  END\\n'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert xyz to mol in rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "\n",
    "\n",
    "mol = Chem.MolFromMolBlock(molblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, atom in enumerate(mol.GetAtoms()):\n",
    "    corr_i = compute_corr[0][ind]\n",
    "    atom.SetProp(\"atomNote\", \"corr: {:.2f}\".format(corr_i))\n",
    "\n",
    "# show hhydrogens in plot\n",
    "# mol = Chem.AddHs(mol)\n",
    "size = (240, 240)\n",
    "fig = Draw.ShowMol(\n",
    "    mol, \n",
    "    size=size, \n",
    "    kekulize=False, \n",
    "    wedgeBonds=False, \n",
    "    showAtomNumbers=False,\n",
    "    options=\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_at_each_layer(model, graph, feats, reactions, norm_atom, norm_bond, target):\n",
    "    \"\"\"\n",
    "    Get the features at each layer before the final fully-connected layer.\n",
    "\n",
    "    This is used for feature visualization to see how the model learns.\n",
    "\n",
    "    Returns:\n",
    "        dict: (layer_idx, feats), each feats is a list of\n",
    "    \"\"\"\n",
    "\n",
    "    layer_idx = 0\n",
    "    bond_grads = {}\n",
    "    atom_grads = {}\n",
    "    global_grads = {}\n",
    "\n",
    "    pred = model(\n",
    "        graph=graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "    )\n",
    "    dict_grads = {\"embedding\": {}, \"gated\": {}}\n",
    "\n",
    "    model.loss(pred.view(-1), target).backward()\n",
    "    linear_index = 0\n",
    "    dict_grads[\"embedding\"][\"atom\"] = model.embedding.linears[\"atom\"].weight.grad\n",
    "    dict_grads[\"embedding\"][\"bond\"] = model.embedding.linears[\"bond\"].weight.grad\n",
    "    dict_grads[\"embedding\"][\"global\"] = model.embedding.linears[\"global\"].weight.grad\n",
    "\n",
    "    # gated layer\n",
    "    for layer in model.gated_layers:\n",
    "        for name, param in layer.A.named_parameters():\n",
    "            dict_grads[\"gated\"][\"A_\" + name] = param.grad\n",
    "        for name, param in layer.B.named_parameters():\n",
    "            dict_grads[\"gated\"][\"B_\" + name] = param.grad\n",
    "        for name, param in layer.C.named_parameters():\n",
    "            dict_grads[\"gated\"][\"C_\" + name] = param.grad\n",
    "        for name, param in layer.D.named_parameters():\n",
    "            dict_grads[\"gated\"][\"D_\" + name] = param.grad\n",
    "        for name, param in layer.E.named_parameters():\n",
    "            dict_grads[\"gated\"][\"E_\" + name] = param.grad\n",
    "        for name, param in layer.F.named_parameters():\n",
    "            dict_grads[\"gated\"][\"F_\" + name] = param.grad\n",
    "        for name, param in layer.G.named_parameters():\n",
    "            dict_grads[\"gated\"][\"G_\" + name] = param.grad\n",
    "        for name, param in layer.H.named_parameters():\n",
    "            dict_grads[\"gated\"][\"H_\" + name] = param.grad\n",
    "        for name, param in layer.I.named_parameters():\n",
    "            dict_grads[\"gated\"][\"I_\" + name] = param.grad\n",
    "\n",
    "    return dict_grads\n",
    "\n",
    "\n",
    "dict_grads = grad_at_each_layer(\n",
    "    model=model_restart,\n",
    "    graph=batched_graph,\n",
    "    feats=feats,\n",
    "    reactions=reactions,\n",
    "    norm_atom=norm_atom,\n",
    "    norm_bond=norm_bond,\n",
    "    target=target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# this operates at the node level???\n",
    "# this is just what nodes are activated\n",
    "def saliency_map(input_grads):\n",
    "    node_saliency_map = []\n",
    "    for n in range(input_grads.shape[0]):  # nth node\n",
    "        node_grads = input_grads[n, :]\n",
    "        node_saliency = torch.norm(F.relu(node_grads)).item()\n",
    "        node_saliency_map.append(node_saliency)\n",
    "    return node_saliency_map\n",
    "\n",
    "\n",
    "def grad_cam(final_conv_acts, final_conv_grads):\n",
    "    # print('grad_cam')\n",
    "    node_heat_map = []\n",
    "    alphas = torch.mean(\n",
    "        final_conv_grads, axis=0\n",
    "    )  # mean gradient for each feature (512x1)\n",
    "    for n in range(final_conv_acts.shape[0]):  # nth node\n",
    "        node_heat = F.relu(alphas @ final_conv_acts[n]).item()\n",
    "        node_heat_map.append(node_heat)\n",
    "    return node_heat_map\n",
    "\n",
    "\n",
    "def ugrad_cam(n_atoms, final_conv_acts, final_conv_grads):\n",
    "    # print('new_grad_cam')\n",
    "    node_heat_map = []\n",
    "    alphas = torch.mean(\n",
    "        final_conv_grads, axis=0\n",
    "    )  # mean gradient for each feature (512x1)\n",
    "    for n in range(final_conv_acts.shape[0]):  # nth node\n",
    "        node_heat = (alphas @ final_conv_acts[n]).item()\n",
    "        node_heat_map.append(node_heat)\n",
    "\n",
    "    node_heat_map = np.array(node_heat_map[:n_atoms]).reshape(-1, 1)\n",
    "    pos_node_heat_map = (\n",
    "        MinMaxScaler(feature_range=(0, 1))\n",
    "        .fit_transform(node_heat_map * (node_heat_map >= 0))\n",
    "        .reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    neg_node_heat_map = (\n",
    "        MinMaxScaler(feature_range=(-1, 0))\n",
    "        .fit_transform(node_heat_map * (node_heat_map < 0))\n",
    "        .reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return pos_node_heat_map + neg_node_heat_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
